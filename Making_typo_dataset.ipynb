{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fh9d4T-jRjH",
        "outputId": "dc55cec1-856e-4209-b43e-ce164386d2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Make sure to download the punkt tokenizer data\n",
        "\n",
        "def text_to_sentences(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "file_path = '/content/big.txt'\n",
        "sentences = text_to_sentences(file_path)\n",
        "\n",
        "# for sentence in sentences:\n",
        "#     print(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_selected_sentences(sentences, output_file):\n",
        "    selected_sentences = sentences[2000:5000]\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        for sentence in selected_sentences:\n",
        "            file.write(sentence + '\\n')\n",
        "\n",
        "output_file = 'source.txt'\n",
        "save_selected_sentences(sentences, output_file)"
      ],
      "metadata": {
        "id": "SaG1nZ8cmf3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_sentences=sentences[2000:5000]"
      ],
      "metadata": {
        "id": "BRvi0wFBkHma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save in csv file IMPORTANT"
      ],
      "metadata": {
        "id": "LMuN_Cav2IFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def replace_words_in_sentence(sentence, replacements, key):\n",
        "    changes = []\n",
        "    num_changes = 0\n",
        "    for replacement in replacements.get(key, []):  # Check if the key exists in replacements\n",
        "        if f\" {key} \" in sentence:\n",
        "            sentence = sentence.replace(f\" {key} \", f\" {replacement} \")\n",
        "            changes.append((key, replacement))\n",
        "            num_changes += 1\n",
        "        elif sentence.startswith(key + \" \") and sentence[len(key)] == \" \":\n",
        "            sentence = sentence.replace(key + \" \", replacement + \" \", 1)\n",
        "            changes.append((key, replacement))\n",
        "            num_changes += 1\n",
        "        elif sentence.endswith(\" \" + key) and sentence[-len(key) - 1] == \" \":\n",
        "            sentence = sentence[::-1].replace(key[::-1] + \" \", replacement[::-1] + \" \", 1)[::-1]\n",
        "            changes.append((key, replacement))\n",
        "            num_changes += 1\n",
        "        elif sentence == key:\n",
        "            sentence = replacement\n",
        "            changes.append((key, replacement))\n",
        "            num_changes += 1\n",
        "    return sentence, num_changes, changes\n",
        "\n",
        "def main():\n",
        "    # Load dictionary\n",
        "    with open('/content/wikipedia.txt', 'r') as dict_file:\n",
        "        replacements = {}\n",
        "        for line in dict_file:\n",
        "            words = line.strip().split(':')\n",
        "            key = words[0].strip()\n",
        "            values = [v.strip() for v in words[1].split()]\n",
        "            replacements[key] = values\n",
        "\n",
        "    # Read source file\n",
        "    with open('/content/source.txt', 'r') as source_file:\n",
        "        source_text = source_file.read()\n",
        "\n",
        "    # Split the source text into sentences\n",
        "    sentences = source_text.split('.')\n",
        "\n",
        "    # Perform replacements sentence by sentence\n",
        "    replaced_sentences = []\n",
        "    with open('replacements.csv', 'w', newline='') as csvfile:\n",
        "        fieldnames = ['original_sentence', 'replaced_sentence', 'replacement', 'number_of_replacements', 'changed_words']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for sentence in sentences:\n",
        "            for key in replacements.keys():\n",
        "                replaced_sentence, num_changes, changes = replace_words_in_sentence(sentence, replacements, key)\n",
        "                if num_changes > 0:  # Write to CSV only if there are changes\n",
        "                    replaced_sentences.append(replaced_sentence)\n",
        "                    writer.writerow({'original_sentence': sentence.strip(),\n",
        "                                     'replaced_sentence': replaced_sentence.strip(),\n",
        "                                     'replacement': 1,\n",
        "                                     'number_of_replacements': num_changes,\n",
        "                                     'changed_words': ', '.join([f'{change[0]}->{change[1]}' for change in changes])})\n",
        "                    break  # Move to the next sentence once replacements are made\n",
        "            else:\n",
        "                replaced_sentences.append(sentence)  # If no replacements, keep the original sentence\n",
        "\n",
        "    # Join the replaced sentences back into text\n",
        "    replaced_text = '. '.join(replaced_sentences) + '.'\n",
        "\n",
        "    # Write replaced text to a new file\n",
        "    with open('replaced.txt', 'w') as replaced_file:\n",
        "        replaced_file.write(replaced_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "AzyEd-2_Ggmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#level of difficulty\n"
      ],
      "metadata": {
        "id": "zhJ4wjHfJcgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/replacements.csv')\n",
        "\n",
        "def random_number():\n",
        "    return random.randint(1, 3)\n",
        "\n",
        "# Add a new column 'level_of_difficulty' with random numbers\n",
        "df['number_changes_wanted'] = [random_number() for _ in range(len(df))]\n"
      ],
      "metadata": {
        "id": "SGBQeLfpJee0"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version3.0"
      ],
      "metadata": {
        "id": "UkcAX6ALyQVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n"
      ],
      "metadata": {
        "id": "JedQ31GWyheE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def case_variaties(word: str) -> list[str]:\n",
        "    'Change the capitalisation of the first two letters'\n",
        "    case_list = []\n",
        "    case_list.append([word.lower(), word])\n",
        "    case_list.append([word.upper(), word])\n",
        "    case_list.append([word[:1].upper() + word[1:], word])\n",
        "    case_list.append([word[:2].upper() + word[2:], word])\n",
        "    return case_list\n",
        "\n",
        "def enter_signs(word: str) -> list[str]:\n",
        "    'add # and + at the end, because of fat fingers when hitting enter'\n",
        "    enter_list = []\n",
        "    enter_list.append([word + '#', word])\n",
        "    enter_list.append([word + '+', word])\n",
        "    return enter_list\n",
        "\n",
        "def no_spaces(word: str) -> str:\n",
        "    'eliminate all spaces from word'\n",
        "    return [[word.replace(' ', ''), word]]\n",
        "\n",
        "def swap_letter(word: str) -> list[str]:\n",
        "    'swap every letter of a word pairwise'\n",
        "    swap_list = []\n",
        "    for idx, letter in enumerate(word):\n",
        "        swap_list.append([word[:idx] + word[idx+1] + word[idx] + word[idx+2:], word])\n",
        "        if idx + 2 == len(word):\n",
        "            break\n",
        "    return swap_list\n",
        "\n",
        "def double_letter(word: str) -> list[str]:\n",
        "    'double every letter in the word'\n",
        "    double_letter_list = []\n",
        "    for idx, letter in enumerate(word):\n",
        "        double_letter_list.append([word[:idx] + letter + word[idx:], word])\n",
        "    return double_letter_list\n",
        "\n",
        "def one_out(word: str) -> list[str]:\n",
        "    'Remove on every possible position one letter from the input word'\n",
        "    one_out = []\n",
        "    for idx in range(len(word)):\n",
        "        one_out.append([word[:idx] + word[idx+1:], word])\n",
        "    return one_out\n",
        "\n",
        "def add_noise(word: str) -> list[str]:\n",
        "    'add a random string with random length at the end of the word'\n",
        "    noise_words = []\n",
        "    for _ in range(6):\n",
        "        noise_words.append([word + ''.join([random.choice(string.ascii_letters) for i in range(random.randint(1, 8))]), word])\n",
        "    return noise_words\n"
      ],
      "metadata": {
        "id": "vFBhycv6yim5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Iterate over each row\n",
        "for index, row in df.iterrows():\n",
        "    changes_wanted = row['number_changes_wanted']\n",
        "    current_replacements = row['number_of_replacements']\n",
        "\n",
        "    if current_replacements < changes_wanted:\n",
        "        # Choose randomly from functions and apply them to unchanged words\n",
        "        original_sentence = row['original_sentence']\n",
        "        changed_sentence = row['replaced_sentence']\n",
        "        before_changed_words=row['changed_words'].split('->')\n",
        "        before_changed_words=before_changed_words[0]\n",
        "        changed_words = row['changed_words'].split('->')\n",
        "        changed_words = changed_words[1]\n",
        "\n",
        "        unchanged_words = [word for word in original_sentence.split() if word not in changed_words and len(word) > 3]\n",
        "\n",
        "        while current_replacements < changes_wanted:\n",
        "            word_to_change = random.choice(unchanged_words)\n",
        "            function_to_apply = random.choice([case_variaties, enter_signs, no_spaces, swap_letter, double_letter, one_out, add_noise])\n",
        "            modified_word = function_to_apply(word_to_change)[0][0]\n",
        "            changed_sentence = changed_sentence.replace(word_to_change, modified_word, 1)\n",
        "            current_replacements += 1\n",
        "            # Initialize changed_words as a list if it's not already\n",
        "            if isinstance(changed_words, str):\n",
        "              changed_words = changed_words + \"->\" + before_changed_words\n",
        "              changed_words = changed_words.split(', ')\n",
        "            changed_words.append(f\"{word_to_change}->{modified_word}\")\n",
        "        # Update DataFrame with modified sentence and number of replacements\n",
        "        df.at[index, 'replaced_sentence'] = changed_sentence\n",
        "        df.at[index, 'number_of_replacements'] = current_replacements\n",
        "        # Update changed_words with newly replaced words\n",
        "\n",
        "\n",
        "        df.at[index, 'changed_words'] = ', '.join(changed_words)\n",
        "# Save the updated DataFrame back to the CSV file\n",
        "df.to_csv('your_file.csv', index=False)\n"
      ],
      "metadata": {
        "id": "qQKd-FtPyR-e"
      },
      "execution_count": 121,
      "outputs": []
    }
  ]
}